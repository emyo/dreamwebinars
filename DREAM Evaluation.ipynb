{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Submissions to the SMC-RNA DREAM Challenge on the Seven Bridges CGC\n",
    "\n",
    "This will go over how to use the API to go from a Task ID to having the submitted application and reference files cached in a new project, then rerunning it with evaluation data. The evaluation data and new project are mocks which can be replaced for the actual evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from os import environ\n",
    "from datetime import datetime\n",
    "import sevenbridges as sbg\n",
    "from dream_helpers import *\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Create API object\n",
    "api = sbg.Api(config=sbg.Config(url=environ['API_URL'], token=environ['AUTH_TOKEN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: task not completed. Current status: RUNNING\n",
      "Task_inputs: \n",
      "{   'TUMOR_FASTQ_1': 'Label indicates TUMOR_FASTQ',\n",
      "    'TUMOR_FASTQ_2': 'Label indicates TUMOR_FASTQ',\n",
      "    'bias': True,\n",
      "    'bootstrap': 30,\n",
      "    'fasta': <File: id=57b5e008e4b0192c34a4ee55>,\n",
      "    'index_filename': u'kallisto_k31_Homo_sapiens.GRCh37.75.cdna.all.index',\n",
      "    'kmer': 31,\n",
      "    'output_prefix': u'sim11',\n",
      "    'threads': 5}\n"
     ]
    }
   ],
   "source": [
    "# task_id=\"6d2becba-c266-4d84-9de5-92b598de1042\" # RSEM with TUMOR_FASTQ in labels (not IDs)\n",
    "# task_id = \"21d6c8f7-d75e-4d57-b1ec-884218becef3\"\n",
    "# task_id = \"3faacf31-b840-465c-9ba0-df85dce4ef6d\"\n",
    "task_id = \"975423f6-ffda-4eae-9935-529d204c496d\"\n",
    "\n",
    "# # Can grab the necessary objects\n",
    "validation_task = api.tasks.get(task_id) # task_object\n",
    "# validation_project = api.projects.get(validation_task.project) # project_object\n",
    "# validation_app = api.apps.get(validation_task.app) # app_object\n",
    "\n",
    "def check_task_status(task_object):\n",
    "    if task_object.status == \"COMPLETED\":\n",
    "        print(\"\\nTask status: Completed.\")\n",
    "    else:\n",
    "        print(\"WARNING: task not completed. Current status: {}\".format(task_object.status))\n",
    "\n",
    "def replace_file_dicts_with_objects(api, project, task_inputs):\n",
    "    for k, v in task_inputs.iteritems():\n",
    "        if isinstance(v, dict) and v[\"class\"] == \"File\":\n",
    "            task_inputs[k] = get_file_by_name(api, project, v[\"name\"])\n",
    "    return task_inputs\n",
    "\n",
    "def empty_tumor_ports_by_id(task_inputs):\n",
    "    for k, v in task_inputs.iteritems():\n",
    "        if \"TUMOR_FASTQ\" in k:\n",
    "            task_inputs[k] = \"ID indicates TUMOR_FASTQ\"\n",
    "    return task_inputs\n",
    "\n",
    "def empty_tumor_ports_by_label(app_object, task_inputs):\n",
    "    for port in app_object.raw['inputs']:\n",
    "        if \"label\" in port and \"TUMOR_FASTQ\".lower() in port['label'].lower():\n",
    "            task_inputs[port['id'].split(\"#\")[-1]] = \"Label indicates TUMOR_FASTQ\"\n",
    "    return task_inputs\n",
    "\n",
    "def get_task_input_object(api, task_id):\n",
    "    task_object = api.tasks.get(task_id)\n",
    "    \n",
    "    # Get required objects\n",
    "    app_object = api.apps.get(task_object.app)\n",
    "    project = api.projects.get(task_object.project)\n",
    "    \n",
    "    # Check if task is successfully completed\n",
    "    check_task_status(task_object)\n",
    "    \n",
    "    # Remove keys where value is None/NoneType\n",
    "    task_inputs = dict((str(k), v) for k, v in task_object.inputs.iteritems() if v)\n",
    "\n",
    "    # Replace the values that represent files (currently dicts) with File object\n",
    "    task_inputs = replace_file_dicts_with_objects(api, project, task_inputs)\n",
    "\n",
    "    # Empty values where TUMOR_FASTQ is in ID or label\n",
    "    task_inputs = empty_tumor_ports_by_id(task_inputs)\n",
    "    task_inputs = empty_tumor_ports_by_label(app_object, task_inputs)\n",
    "\n",
    "    print(\"Task_inputs: \")\n",
    "    pp.pprint(task_inputs)\n",
    "    return task_inputs\n",
    "\n",
    "input_object = get_task_input_object(api, task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gauravdream_rsem_index.tar.gz\n",
      "\n",
      "WARNING: 'gauravdream_rsem_index.tar.gz' already in 'gauravdream/dream-eval' project.\n",
      "\n",
      "No files copied.\n",
      "{   'f': u'\"1,6\"',\n",
      "    'index': <File: id=57a9f513e4b0a2cad67e8581>,\n",
      "    'input': 'Label indicates TUMOR_FASTQ',\n",
      "    'input_1': 'Label indicates TUMOR_FASTQ',\n",
      "    'output_filename': u'rererunning_sim8_rsem_isoform_quant.tsv',\n",
      "    'pairedend': True,\n",
      "    'strandspecific': True,\n",
      "    'threads': 8}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NEXT STEPS\n",
    "- filter through task_inputs, check if file, then copy to new project\n",
    "- copy application to new project [done]\n",
    "- replace input object files with new file objects [done]\n",
    "- rerun a task on a new pair of dummy files\n",
    "- wrap it all up as a command-line runnable\n",
    "\"\"\"\n",
    "# Define Evaluation Project\n",
    "# print(*[p.id for p in get_projects_list(api)], sep=\"\\n\")\n",
    "eval_project = \"gauravdream/dream-eval\" # where you'll do the evaluation of the app\n",
    "\n",
    "# Copy files\n",
    "#     - note that identical files in multiple projects have UNIQUE IDs\n",
    "#     - cannot check to see if the file exists already by ID\n",
    "#     - so we create a new filename that should be unique to the submitter and check on that\n",
    "def copy_to_eval_project(api, task_object, evaluation_project, task_inputs):\n",
    "    \n",
    "    # Initialize new files and new_task_inputs\n",
    "    new_files = []\n",
    "    new_task_inputs = task_inputs.copy() # let's not change the original object\n",
    "    \n",
    "    # 1. Iterate over the keys and values in task_inputs\n",
    "    # 2. Check if it's a file\n",
    "    # 3. Create new_filename\n",
    "    # 4. If file by new_filename not in eval project, copy\n",
    "    # 5. Replace values in new_task_inputs with the new, copied files\n",
    "    # 6. If files were copied, get new_files and new_input_object\n",
    "    for k, obj in task_inputs.iteritems():\n",
    "        \n",
    "        if obj.__class__.__name__ == \"File\":\n",
    "            \n",
    "            submitters_username = task_object.created_by\n",
    "            new_filename = \"_\".join([submitters_username, obj.name]) # e.g gauravdream_rsem_index.tar.gz\n",
    "#             new_filename = \"_\".join([\"test\", obj.name]) # debugging only\n",
    "\n",
    "            # Check if the file with that filename already exists in evaluation project (check_file)\n",
    "            # - if it does,     replace the value in the input object with that file\n",
    "            # - if it does not, copy to new project and set value in input object\n",
    "            check_file = get_file_by_name(api, project=evaluation_project, filename=new_filename)\n",
    "            print(check_file.name)\n",
    "            if check_file:\n",
    "                print(\"\\nWARNING: '{}' already in '{}' project.\".format(new_filename, evaluation_project))\n",
    "                new_task_inputs[k] = check_file # replace file object with object in new project\n",
    "            else:\n",
    "                new_file = obj.copy(project=evaluation_project, name=new_filename)\n",
    "                new_task_inputs[k] = new_file # replace old file object with new one\n",
    "                print(\"\\n'{}' copied to '{}' project \\n\\twith new filename: '{}'\".format(obj.name, evaluation_project, new_filename))\n",
    "                print(\"New file ID: {}\".format(new_file.id))\n",
    "                new_files.append(new_file)\n",
    "    # If there are new_files, return them and the new task inputs object, else warn and return old inputs object\n",
    "    if new_files:\n",
    "        return new_files, new_task_inputs\n",
    "    else:\n",
    "        print(\"\\nNo files copied.\")\n",
    "        return None, new_task_inputs\n",
    "\n",
    "new_files, new_input_object = copy_to_eval_project(api, validation_task, eval_project, input_object)\n",
    "\n",
    "# Print: new filenames\n",
    "if new_files: \n",
    "    print(\"\\nNew filenames in {}:\".format(eval_project))\n",
    "    print(*[f.name for f in new_files], sep=\"\\n\")\n",
    "pp.pprint(new_input_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gauravdream_smcIsoform-RSEM-Workflow_1' app already exists in the 'gauravdream/dream-eval' project. Returning app in evaluation project.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copy the tool to your project\n",
    "- we will take the app and rename it\n",
    "- this will cache the app and prevent the user from potentially making changes after submission\n",
    "- to do this, we grab the raw CWL, modify the label to rename it, and set a new id  with that label\n",
    "- the label is the submitter's username, the original label, and then the version/revision number (sep=\"-\")\n",
    "- this will make sure that each submission is uniquely versioned\n",
    "- we will also do error checking for duplicate apps\n",
    "\"\"\"\n",
    "\n",
    "def copy_app_to_evaluation_project(api, task_object, evaluation_project):\n",
    "    \n",
    "    # Get submission info\n",
    "    submission_app = api.apps.get(task_object.app) # get app_object using task_object\n",
    "    submission_username = task_object.created_by\n",
    "    \n",
    "    # Grab RAW CWL & modify label and id\n",
    "    evaluation_app = submission_app.raw\n",
    "    evaluation_app['label'] = \"_\".join([submission_username, evaluation_app['label'], str(submission_app.revision)])\n",
    "#     evaluation_app['label'] = \"dream_testing_this_code\" # debugging only\n",
    "    evaluation_app_id = \"/\".join([evaluation_project, evaluation_app['label']])\n",
    "\n",
    "    # Try to install the new app -- if it fails, return the app object in the new project\n",
    "    try:\n",
    "        installed_app = api.apps.install_app(raw=evaluation_app, id=evaluation_app_id)\n",
    "        print(\"'{}' app from '{}' installed in '{}' project.\".format(evaluation_app['label'], submission_username, evaluation_project))\n",
    "        return installed_app\n",
    "    except:\n",
    "        print(\"'{}' app already exists in the '{}' project. Returning app in evaluation project.\".format(evaluation_app['label'], evaluation_project))\n",
    "        return get_app_by_name(api, project=evaluation_project, app_name=evaluation_app['label'])\n",
    "\n",
    "new_app = copy_app_to_evaluation_project(api, validation_task, evaluation_project=eval_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good news, everyone! The tuples are paired nicely (by sample id).\n",
      "evaluation_abc123_1.fq.gz\n",
      "evaluation_abc123_2.fq.gz\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grab evaluation fastqs here by metadata \n",
    "- split_fastqs_tuple returns a list of tuples (contains two fastq file objects)\n",
    "- we grab the first element here (should only return list of size=1 for unique sample_id)\n",
    "\"\"\"\n",
    "eval_fastq_metadata = {\"sample_id\":\"evalabc123\"} # just a dummy sample_id\n",
    "eval_fastqs = split_fastqs_tuple(fastqs=get_files_by_metadata(api, eval_project, eval_fastq_metadata))[0]\n",
    "print(*[fq.name for fq in eval_fastqs], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'f': u'\"1,6\"',\n",
      "    'index': <File: id=57b51294e4b0192c34a4ba63>,\n",
      "    'input': 'Label indicates TUMOR_FASTQ',\n",
      "    'input_1': 'Label indicates TUMOR_FASTQ',\n",
      "    'output_filename': u'rererunning_sim8_rsem_isoform_quant.tsv',\n",
      "    'pairedend': True,\n",
      "    'strandspecific': True,\n",
      "    'threads': 8}\n",
      "{   'f': u'\"1,6\"',\n",
      "    'index': <File: id=57b51294e4b0192c34a4ba63>,\n",
      "    'input': <File: id=57b48e55e4b0192c34a4b993>,\n",
      "    'input_1': <File: id=57b48e55e4b0192c34a4b992>,\n",
      "    'output_filename': u'rererunning_sim8_rsem_isoform_quant.tsv',\n",
      "    'pairedend': True,\n",
      "    'strandspecific': True,\n",
      "    'threads': 8}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(new_input_object)\n",
    "\"\"\"\n",
    "Insert evaluation fastqs in input_object\n",
    "\"\"\"\n",
    "\n",
    "def insert_evaluation_fastqs_into_object(evaluation_fastqs, task_inputs):\n",
    "    new_task_inputs = task_inputs.copy()\n",
    "    fastqs = list(evaluation_fastqs)\n",
    "    while fastqs:\n",
    "        for k, val in new_task_inputs.iteritems():\n",
    "            if type(val) == str and \"TUMOR_FASTQ\" in val: \n",
    "                new_task_inputs[k] = fastqs[-1]\n",
    "                fastqs.pop()\n",
    "    return new_task_inputs\n",
    "\n",
    "new_input_object = insert_evaluation_fastqs_into_object(eval_fastqs, new_input_object)\n",
    "pp.pprint(new_input_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'f': u'\"1,6\"',\n",
      "    'index': u'gauravdream_rsem_index.tar.gz',\n",
      "    'input': u'evaluation_abc123_1.fq.gz',\n",
      "    'input_1': u'evaluation_abc123_2.fq.gz',\n",
      "    'output_filename': u'rererunning_sim8_rsem_isoform_quant.tsv',\n",
      "    'pairedend': True,\n",
      "    'strandspecific': True,\n",
      "    'threads': 8}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Final sanity check\n",
    "- print final input object names to check filenames\n",
    "\"\"\"\n",
    "names_dict = new_input_object.copy()\n",
    "for k, v in names_dict.iteritems():\n",
    "    if v.__class__.__name__ == \"File\":\n",
    "        names_dict[k] = v.name\n",
    "pp.pprint(names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task created: Evaluation_gauravdream_smcIsoform-RSEM-Workflow_1_evalabc123 - 08-17-2016 22:57:52\n",
      "\n",
      "Input files: evaluation_abc123_1.fq.gz, evaluation_abc123_2.fq.gz\n",
      "\n",
      "Input object: \n",
      "{   'f': u'\"1,6\"',\n",
      "    'index': <File: id=57b51294e4b0192c34a4ba63>,\n",
      "    'input': <File: id=57b48e55e4b0192c34a4b993>,\n",
      "    'input_1': <File: id=57b48e55e4b0192c34a4b992>,\n",
      "    'output_filename': u'rererunning_sim8_rsem_isoform_quant.tsv',\n",
      "    'pairedend': True,\n",
      "    'strandspecific': True,\n",
      "    'threads': 8}\n"
     ]
    }
   ],
   "source": [
    "# Create individualized task names with sample ID and current time\n",
    "sample_id = eval_fastqs[0].metadata['sample_id']\n",
    "current_time = datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "eval_task_name = \"Evaluation_{}_{} - {}\".format(new_app.name, sample_id, current_time)\n",
    "\n",
    "# Create the task\n",
    "debug = False\n",
    "if not debug:\n",
    "    new_task = api.tasks.create(name=eval_task_name, \n",
    "                     project=eval_project,\n",
    "                     app=new_app, \n",
    "                     inputs=new_input_object,\n",
    "                     run=True) # IMPORTANT! set run=True if you want to run, not just draft the tasks\n",
    "print(\"\\nTask created: {}\".format(eval_task_name))\n",
    "print(\"\\nInput files: {}, {}\".format(eval_fastqs[0].name, eval_fastqs[1].name))\n",
    "print(\"\\nInput object: \")\n",
    "pp.pprint(new_input_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
